{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ProjectCode.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "klZ8xR1-rhGg",
        "colab_type": "code",
        "outputId": "be0e0ae3-7331-428e-9a36-37c0f2b4fddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "!pip install pymorphy2\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import pymorphy2\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from sklearn.semi_supervised import LabelSpreading, LabelPropagation"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhjEP49DtBLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju5GplVFrhGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "linkrev = 'https://drive.google.com/open?id=10KALb9_A15D0589m1EYiRmUypakFGPaA'\n",
        "fluff, id = linkrev.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('rest_train.xml')  \n",
        "tree = ET.parse('rest_train.xml')\n",
        "root = tree.getroot()\n",
        "df = pd.DataFrame(columns = ['food_score', 'interior_score', 'service_score', 'review'])\n",
        "for i in range(19034):\n",
        "    df.loc[i] = [root[i][1][0].text,root[i][1][1].text,root[i][1][2].text,root[i][2].text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkcbqJbCt4JQ",
        "colab_type": "code",
        "outputId": "e3690073-e1ea-4a4a-b5fa-c0e829da815b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "linkser = \"https://drive.google.com/open?id=14o5GJQgZqN03Tc51LzKYb6sa650iOCRw\"\n",
        "fluff, id = linkser.split('=')\n",
        "downloaded2 = drive.CreateFile({'id':id}) \n",
        "downloaded2.GetContentFile('Service_words.csv')\n",
        "service = pd.read_csv('Service_words.csv', sep = \"\\\\t\", names = ['aspect', 'word', 'label'], encoding = 'utf-8')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFgqc-TsrhG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linkfood = 'https://drive.google.com/open?id=18bRE2WnURDKHdWoZG-rlaiinLxjIVX_w'\n",
        "fluff, id = linkfood.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Food_words.csv')\n",
        "food = pd.read_csv('Food_words.csv', sep = \";\",   names = ['aspect', 'word', 'label'], encoding = 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w89YKimWrhHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "morph = pymorphy2.MorphAnalyzer()\n",
        "stopWords = stopwords.words('russian')\n",
        "def preproc(text):\n",
        "    tokenized = []\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        p = morph.parse(word)[0]\n",
        "        tokenized.append(p.normal_form)\n",
        "    tokenized = [token for token in tokenized if token not in stopWords\\\n",
        "                and token.strip() not in punctuation]\n",
        "    return tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTFK95awrhHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#можно не запускать, если уже загружена модель\n",
        "reviews = df['review'].tolist()\n",
        "sents = []\n",
        "for review in reviews:\n",
        "  tokreview = sent_tokenize(review)\n",
        "  for sent in tokreview:\n",
        "    toksent = preproc(sent)\n",
        "    sents.append(toksent)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE9owr4F8A6P",
        "colab_type": "code",
        "outputId": "8cdb6721-0b99-4b8e-b34f-bc45e7c86fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "modeltrain = Word2Vec(sents, size=200, window=3, min_count=2, iter=10)\n",
        "modeltrain.save(\"word2vec.model\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3TRZ2tH-9xb",
        "colab_type": "code",
        "outputId": "e7851b1a-710b-4f82-84ef-e883f36627e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model = Word2Vec.load(\"word2vec.model\")\n",
        "allwords2 = model.wv.vocab"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unSZAhwkBaOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aspectstrainlabels = []\n",
        "allwords = []\n",
        "for k, v in allwords2.items():\n",
        "  allwords.append(model.wv[k])\n",
        "  if k in service['word'].tolist():\n",
        "    aspectstrainlabels.append(1)\n",
        "  elif k in food['word'].tolist():\n",
        "    aspectstrainlabels.append(0)\n",
        "  else:\n",
        "    aspectstrainlabels.append(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8hOSCG1rhHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_spr = LabelSpreading(kernel='knn', n_neighbors=5, max_iter = 30)\n",
        "labelsenttest = labeled_spr.fit(allwords, aspectstrainlabels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozVuSTOrLkZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordstest = [i for i in allwords2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6SVGB5uFOSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foodwords = []\n",
        "servicewords = []\n",
        "for i in range(len(labelsenttest.transduction_)):\n",
        "  if labelsenttest.transduction_[i] == 0:\n",
        "    foodwords.append(wordstest[i])\n",
        "  elif labelsenttest.transduction_[i] == 1:\n",
        "    servicewords.append(wordstest[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE47J8F0PUdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foodneg = food[lambda x: x['label'] == 0]['word'].tolist()\n",
        "foodaff = food[lambda x: x['label'] == 1]['word'].tolist()\n",
        "servneg = service[lambda x: x['label'] == 0]['word'].tolist()\n",
        "servaff = service[lambda x: x['label'] == 1]['word'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUpYqqtQlumd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delw (ml, dell):\n",
        "  for word in dell:\n",
        "    if word in ml:\n",
        "      ml.remove(word)\n",
        "  return ml\n",
        "foodwords = delw(foodwords, foodneg)\n",
        "foodwords = delw(foodwords, foodaff)\n",
        "servicewords = delw(foodwords, servneg)\n",
        "servicewords = delw(foodwords, servaff)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0YjxVLKIXiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foodwordsvecs = []\n",
        "servicewordsvecs = []\n",
        "for fword in foodwords:\n",
        "  foodwordsvecs.append(model.wv[fword])\n",
        "for sword in servicewords:\n",
        "  servicewordsvecs.append(model.wv[sword])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g--JvdWVM8ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foodnegdicti = defaultdict(int)\n",
        "foodaffdicti = defaultdict(int)\n",
        "servicenegdicti = defaultdict(int)\n",
        "serviceaffdicti = defaultdict(int)\n",
        "for word in foodneg:\n",
        "  foodnegdicti[word] = 0\n",
        "for word in foodaff:\n",
        "  foodaffdicti[word] = 0\n",
        "for word in servneg:\n",
        "  servicenegdicti[word] = 0\n",
        "for word in servaff:\n",
        "  serviceaffdicti[word] = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij_-cRwgptab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dist(x,y):   \n",
        "    return np.sqrt(np.sum((x-y)**2))\n",
        "\n",
        "def addtosentiment(dictionary, somewords):\n",
        "  newword = ''\n",
        "  distance = 100000000000000000000000000000000\n",
        "  for word, vec in dictionary.items():\n",
        "    for food in somewords:\n",
        "      newdistance = dist(model.wv[word], model.wv[food])\n",
        "      if vec + newdistance < distance:\n",
        "        distance = vec + newdistance\n",
        "        newword = food\n",
        "  somewords.remove(newword)\n",
        "  dictionary[newword] = distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn7lSfPipf-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while len(foodnegdicti) < 100:\n",
        "  addtosentiment(foodnegdicti, foodwords)\n",
        "while len(foodnegdicti) < 100:\n",
        "  addtosentiment(foodaffdicti, foodwords)\n",
        "while len(foodnegdicti) < 100:\n",
        "  addtosentiment(servicenegdicti, servicewords)\n",
        "while len(foodnegdicti) < 100:\n",
        "  addtosentiment(serviceaffdicti, servicewords)\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpRGjZz-WJqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def razmetkamaker (text, output):\n",
        "  f = open(output, \"a\")\n",
        "  tokreview = sent_tokenize(text)\n",
        "  for sent in tokreview:\n",
        "    toksent = preproc(sent)\n",
        "    sents.append(toksent)\n",
        "  for s in range(len(sents)):\n",
        "    for w in range(len(sents[s])):\n",
        "      if sents[s][w] in servicewordsneg:\n",
        "        string = str(s+1) + '\\\\t' + str(w+1) +'\\\\t' + 'service' + '\\\\t' + '0' + '\\\\n'\n",
        "        f.write(string)\n",
        "      elif sents[s][w] in servicewordsaff:\n",
        "        string = str(s+1) + '\\\\t' + str(w+1) +'\\\\t' + 'service' + '\\\\t' + '1' + '\\\\n'\n",
        "        f.write(string)\n",
        "      elif sents[s][w] in foodwordsneg:\n",
        "        string = str(s+1) + '\\\\t' + str(w+1) +'\\\\t' + 'food' + '\\\\t' + '0' + '\\\\n'\n",
        "        f.write(string)\n",
        "      elif sents[s][w] in foodwordsaff:\n",
        "        string = str(s+1) + '\\\\t' + str(w+1) +'\\\\t' + 'food' + '\\\\t' + '1' + '\\\\n'\n",
        "        f.write(string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jamp2ivcL8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}