{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ProjectCode.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "klZ8xR1-rhGg",
        "colab_type": "code",
        "outputId": "2fd1f556-9f75-4946-e774-9cd7d8fefbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "!pip install pymorphy2\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import pymorphy2\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from sklearn.semi_supervised import LabelSpreading, LabelPropagation"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhjEP49DtBLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju5GplVFrhGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "linkrev = 'https://drive.google.com/open?id=10KALb9_A15D0589m1EYiRmUypakFGPaA'\n",
        "fluff, id = linkrev.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('rest_train.xml')  \n",
        "tree = ET.parse('rest_train.xml')\n",
        "root = tree.getroot()\n",
        "df = pd.DataFrame(columns = ['food_score', 'interior_score', 'service_score', 'review'])\n",
        "for i in range(19034):\n",
        "    df.loc[i] = [root[i][1][0].text,root[i][1][1].text,root[i][1][2].text,root[i][2].text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkcbqJbCt4JQ",
        "colab_type": "code",
        "outputId": "27fb5944-0a43-427b-f729-68870819a8a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "linkser = \"https://drive.google.com/open?id=14o5GJQgZqN03Tc51LzKYb6sa650iOCRw\"\n",
        "fluff, id = linkser.split('=')\n",
        "downloaded2 = drive.CreateFile({'id':id}) \n",
        "downloaded2.GetContentFile('Service_words.csv')\n",
        "service = pd.read_csv('Service_words.csv', sep = \"\\\\t\", names = ['aspect', 'word', 'label'], encoding = 'utf-8')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFgqc-TsrhG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linkfood = 'https://drive.google.com/open?id=18bRE2WnURDKHdWoZG-rlaiinLxjIVX_w'\n",
        "fluff, id = linkfood.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Food_words.csv')\n",
        "food = pd.read_csv('Food_words.csv', sep = \";\",   names = ['aspect', 'word', 'label'], encoding = 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w89YKimWrhHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "morph = pymorphy2.MorphAnalyzer()\n",
        "stopWords = stopwords.words('russian')\n",
        "def preproc(text):\n",
        "    tokenized = []\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        p = morph.parse(word)[0]\n",
        "        tokenized.append(p.normal_form)\n",
        "    tokenized = [token for token in tokenized if token not in stopWords\\\n",
        "                and token.strip() not in punctuation]\n",
        "    return tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTFK95awrhHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#можно не запускать, если уже загружена модель\n",
        "reviews = df['review'].tolist()\n",
        "sents = []\n",
        "for review in reviews:\n",
        "  tokreview = sent_tokenize(review)\n",
        "  for sent in tokreview:\n",
        "    toksent = preproc(sent)\n",
        "    sents.append(toksent)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE9owr4F8A6P",
        "colab_type": "code",
        "outputId": "8f9f2a59-fa70-4207-af94-831eee7eb5e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "modeltrain = Word2Vec(sents, size=200, window=3, min_count=2, iter=10)\n",
        "modeltrain.save(\"word2vec.model\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3TRZ2tH-9xb",
        "colab_type": "code",
        "outputId": "85b8af21-e901-49d8-9ea3-5580cba56a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model = Word2Vec.load(\"word2vec.model\")\n",
        "allwords2 = model.wv.vocab"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unSZAhwkBaOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aspectstrainlabels = []\n",
        "allwords = []\n",
        "for k, v in allwords2.items():\n",
        "  allwords.append(model.wv[k])\n",
        "  if k in service['word'].tolist():\n",
        "    aspectstrainlabels.append(1)\n",
        "  elif k in food['word'].tolist():\n",
        "    aspectstrainlabels.append(0)\n",
        "  else:\n",
        "    aspectstrainlabels.append(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8hOSCG1rhHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "719301c1-63be-4f0b-96fc-8f6abbf60e12"
      },
      "source": [
        "labeled_spr = LabelSpreading(kernel='knn', n_neighbors=5, max_iter = 30)\n",
        "labelsenttest = labeled_spr.fit(allwords, aspectstrainlabels)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
            "  self.label_distributions_ /= normalizer\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozVuSTOrLkZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordstest = [i for i in allwords2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6SVGB5uFOSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foodwords = []\n",
        "servicewords = []\n",
        "for i in range(len(labelsenttest.transduction_)):\n",
        "  if labelsenttest.transduction_[i] == 0:\n",
        "    foodwords.append(wordstest[i])\n",
        "  elif labelsenttest.transduction_[i] == 1:\n",
        "    servicewords.append(wordstest[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE47J8F0PUdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foodneg = food[lambda x: x['label'] == 0]['word'].tolist()\n",
        "foodaff = food[lambda x: x['label'] == 1]['word'].tolist()\n",
        "servneg = service[lambda x: x['label'] == 0]['word'].tolist()\n",
        "servaff = service[lambda x: x['label'] == 1]['word'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUpYqqtQlumd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delw (ml, dell):\n",
        "  for word in dell:\n",
        "    if word in ml:\n",
        "      ml.remove(word)\n",
        "  return ml\n",
        "servaff.remove('веселый')\n",
        "foodwords = delw(foodwords, foodneg)\n",
        "foodwords = delw(foodwords, foodaff)\n",
        "servicewords = delw(servicewords, servneg)\n",
        "servicewords = delw(servicewords, servaff)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmC2tO8rJkMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0YjxVLKIXiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foodwordsvecs = []\n",
        "servicewordsvecs = []\n",
        "for fword in foodwords:\n",
        "  foodwordsvecs.append(model.wv[fword])\n",
        "for sword in servicewords:\n",
        "  servicewordsvecs.append(model.wv[sword])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g--JvdWVM8ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foodnegdicti = defaultdict(int)\n",
        "foodaffdicti = defaultdict(int)\n",
        "servicenegdicti = defaultdict(int)\n",
        "serviceaffdicti = defaultdict(int)\n",
        "for word in foodneg:\n",
        "  foodnegdicti[word] = 0\n",
        "for word in foodaff:\n",
        "  foodaffdicti[word] = 0\n",
        "for word in servneg:\n",
        "  servicenegdicti[word] = 0\n",
        "for word in servaff:\n",
        "  serviceaffdicti[word] = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yuw_09srMTcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "4371c91e-cc11-4982-98ec-e51836d615e2"
      },
      "source": [
        "foodaffdicti"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'большой': 0,\n",
              "             'великолепный': 0,\n",
              "             'вкусный': 0,\n",
              "             'горячий': 0,\n",
              "             'достойный': 0,\n",
              "             'единственный': 0,\n",
              "             'интересный': 0,\n",
              "             'необычный': 0,\n",
              "             'отличный': 0,\n",
              "             'понравиться': 0,\n",
              "             'прекрасный': 0,\n",
              "             'приятный': 0,\n",
              "             'различный': 0,\n",
              "             'разнообразный': 0,\n",
              "             'свежий': 0,\n",
              "             'странный': 0,\n",
              "             'сытный': 0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij_-cRwgptab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dist(x,y):   \n",
        "    return np.sqrt(np.sum((x-y)**2))\n",
        "\n",
        "def addtosentiment(dictionary, somewords):\n",
        "  newword = ''\n",
        "  distance = 100000000000000000000000000000000\n",
        "  for word, vec in dictionary.items():\n",
        "    for food in somewords:\n",
        "      newdistance = dist(model.wv[word], model.wv[food])\n",
        "      if vec + newdistance < distance:\n",
        "        distance = vec + newdistance\n",
        "        newword = food\n",
        "  somewords.remove(newword)\n",
        "  dictionary[newword] = distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa5pUMflDofO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makedistdicti(allw, negdict, affdict):\n",
        "  for word in allw:\n",
        "    negword = ''\n",
        "    affword = ''\n",
        "    distneg = 100000000000000000000000000000\n",
        "    distaff = 100000000000000000000000000000\n",
        "    for nword, vec in negdict.items():\n",
        "      newdistance = dist(model.wv[nword], model.wv[word])\n",
        "      if vec + newdistance < distneg:\n",
        "        distneg  = vec + newdistance\n",
        "        negword = word\n",
        "\n",
        "    for aword, vec in affdict.items():\n",
        "      newdistance = dist(model.wv[aword], model.wv[word])\n",
        "      if vec + newdistance < distaff:\n",
        "        distaff  = vec + newdistance\n",
        "        affword = word\n",
        "\n",
        "    negdict[negword] = distneg\n",
        "    affdict[affword] = distaff\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn7lSfPipf-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "makedistdicti(foodwords, foodnegdicti, foodaffdicti)\n",
        "makedistdicti(servicewords, servicenegdicti, serviceaffdicti)\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlT2X1_m_2Ff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentdictmaker(my_dict):\n",
        "  new_dict = sorted(my_dict.items(), key=lambda item: item[1])\n",
        "  sentdicti = []\n",
        "  i = 0\n",
        "  for v, k in new_dict:\n",
        "    if i < 100:\n",
        "      sentdicti.append(v)\n",
        "    i+=1\n",
        "  return sentdicti\n",
        "\n",
        "negfw = sentdictmaker(foodnegdicti)\n",
        "afffw = sentdictmaker(foodaffdicti)\n",
        "negsw = sentdictmaker(servicenegdicti)\n",
        "affsw = sentdictmaker(serviceaffdicti)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpRGjZz-WJqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def razmetkamaker (text, output, servicewordsneg, servicewordsaff, foodwordsneg, foodwordsaff):\n",
        "  f = open(output, \"a\")\n",
        "  tokreview = sent_tokenize(text)\n",
        "  for sent in tokreview:\n",
        "    toksent = preproc(sent)\n",
        "    sents.append(toksent)\n",
        "  for s in range(len(sents)):\n",
        "    for w in range(len(sents[s])):\n",
        "      if sents[s][w] in servicewordsneg & not in servicewordsaff:\n",
        "        string = str(s+1) + '\\\\t' + str(w+1) +'\\\\t' + 'service' + '\\\\t' + '0' + '\\\\n'\n",
        "        f.write(string)\n",
        "      elif sents[s][w] in servicewordsaff & not in servicewordsneg:\n",
        "        string = str(s+1) + '\\\\t' + str(w+1) +'\\\\t' + 'service' + '\\\\t' + '1' + '\\\\n'\n",
        "        f.write(string)\n",
        "      elif sents[s][w] in foodwordsneg & not in foodwordsaff:\n",
        "        string = str(s+1) + '\\\\t' + str(w+1) +'\\\\t' + 'food' + '\\\\t' + '0' + '\\\\n'\n",
        "        f.write(string)\n",
        "      elif sents[s][w] in foodwordsaff & not in foodwordsneg:\n",
        "        string = str(s+1) + '\\\\t' + str(w+1) +'\\\\t' + 'food' + '\\\\t' + '1' + '\\\\n'\n",
        "        f.write(string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jamp2ivcL8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}