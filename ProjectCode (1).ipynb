{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ProjectCode.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "klZ8xR1-rhGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "bef862bf-607e-4627-b188-b24d8fd56823"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "!pip install pymorphy2\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import pymorphy2\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from sklearn.semi_supervised import LabelSpreading"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhjEP49DtBLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju5GplVFrhGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "linkrev = 'https://drive.google.com/open?id=10KALb9_A15D0589m1EYiRmUypakFGPaA'\n",
        "fluff, id = linkrev.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('rest_train.xml')  \n",
        "tree = ET.parse('rest_train.xml')\n",
        "root = tree.getroot()\n",
        "df = pd.DataFrame(columns = ['food_score', 'interior_score', 'service_score', 'review'])\n",
        "for i in range(19034):\n",
        "    df.loc[i] = [root[i][1][0].text,root[i][1][1].text,root[i][1][2].text,root[i][2].text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkcbqJbCt4JQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4bcf0959-f160-41af-e961-5d033bcf2170"
      },
      "source": [
        "linkser = \"https://drive.google.com/open?id=14o5GJQgZqN03Tc51LzKYb6sa650iOCRw\"\n",
        "fluff, id = linkser.split('=')\n",
        "downloaded2 = drive.CreateFile({'id':id}) \n",
        "downloaded2.GetContentFile('Service_words.csv')\n",
        "service = pd.read_csv('Service_words.csv', sep = \"\\\\t\", names = ['aspect', 'word', 'label'], encoding = 'utf-8')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFgqc-TsrhG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linkfood = 'https://drive.google.com/open?id=18bRE2WnURDKHdWoZG-rlaiinLxjIVX_w'\n",
        "fluff, id = linkfood.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Food_words.csv')\n",
        "food = pd.read_csv('Food_words.csv', sep = \";\",   names = ['aspect', 'word', 'label'], encoding = 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w89YKimWrhHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "morph = pymorphy2.MorphAnalyzer()\n",
        "stopWords = stopwords.words('russian')\n",
        "def preproc(text):\n",
        "    tokenized = []\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        p = morph.parse(word)[0]\n",
        "        tokenized.append(p.normal_form)\n",
        "    tokenized = [token for token in tokenized if token not in stopWords\\\n",
        "                and token.strip() not in punctuation]\n",
        "    return tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTFK95awrhHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#можно не запускать, уэе загружена модель в \n",
        "reviews = df['review'].tolist()\n",
        "sents = []\n",
        "for review in reviews:\n",
        "  tokreview = sent_tokenize(review)\n",
        "  for sent in tokreview:\n",
        "    toksent = preproc(sent)\n",
        "    sents.append(toksent)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE9owr4F8A6P",
        "colab_type": "code",
        "outputId": "b4b0e8bb-29b2-4726-b135-d5ac241eb918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "modeltrain = Word2Vec(sents, size=200, window=3, min_count=2, iter=10)\n",
        "modeltrain.save(\"word2vec.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3TRZ2tH-9xb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c28ab462-65c4-4585-8c9a-dfbbfd8bdaf6"
      },
      "source": [
        "model = Word2Vec.load(\"word2vec.model\")\n",
        "allwords2 = model.wv.vocab"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unSZAhwkBaOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aspectstrainlabels = []\n",
        "allwords = []\n",
        "for k, v in allwords2.items():\n",
        "  allwords.append(model.wv[k])\n",
        "  if k in service['word'].tolist():\n",
        "    aspectstrainlabels.append(1)\n",
        "  elif k in food['word'].tolist():\n",
        "    aspectstrainlabels.append(0)\n",
        "  else:\n",
        "    aspectstrainlabels.append(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8hOSCG1rhHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f4e207f4-8e55-4466-c11c-b95cf0e27397"
      },
      "source": [
        "labeled_spr = LabelSpreading(kernel='knn', n_neighbors=5, max_iter = 10)\n",
        "labelsenttest = labeled_spr.fit(allwords, aspectstrainlabels)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
            "  self.label_distributions_ /= normalizer\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozVuSTOrLkZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordstest = [i for i in allwords2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6SVGB5uFOSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foodwords = []\n",
        "servicewords = []\n",
        "for i in range(len(labelsenttest.transduction_)):\n",
        "  if labelsenttest.transduction_[i] == 0:\n",
        "    foodwords.append(wordstest[i])\n",
        "  elif labelsenttest.transduction_[i] == 1:\n",
        "    servicewords.append(wordstest[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE47J8F0PUdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foodneg = food[lambda x: x['label'] == 0]['word'].tolist()\n",
        "foodaff = food[lambda x: x['label'] == 1]['word'].tolist()\n",
        "servneg = service[lambda x: x['label'] == 0]['word'].tolist()\n",
        "servaff = service[lambda x: x['label'] == 1]['word'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfgkT20TJ7YX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f7903fea-02ba-4d9a-b2f2-91ffe723282d"
      },
      "source": [
        "foodsenttrain = []\n",
        "foodvecs = []\n",
        "for word in foodwords:\n",
        "  foodvecs.append(model.wv[word])\n",
        "  if word in foodaff:\n",
        "    foodsenttrain.append(1)\n",
        "  elif word in foodneg:\n",
        "    foodsenttrain.append(0)\n",
        "  else:\n",
        "    foodsenttrain.append(-1)\n",
        "labeling = LabelSpreading(kernel='knn', n_neighbors=5, max_iter = 2)\n",
        "labelfood = labeling.fit(foodvecs, foodsenttrain)\n",
        "labelfood.transduction_"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:288: ConvergenceWarning: max_iter=2 was reached without convergence.\n",
            "  category=ConvergenceWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
            "  self.label_distributions_ /= normalizer\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZqxNnUCLREv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "servicesenttrain = []\n",
        "servicevecs = []\n",
        "for word in servicewords:\n",
        "  servicevecs.append(model.wv[word])\n",
        "  if word in servaff:\n",
        "    servicesenttrain.append(1)\n",
        "  elif word in servneg:\n",
        "    servicesenttrain.append(0)\n",
        "  else:\n",
        "    servicesenttrain.append(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRGyndBsVezo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "41db86c3-8860-494a-9735-6c1daf920b3c"
      },
      "source": [
        "labeling = LabelSpreading(kernel='knn', n_neighbors=5, max_iter = 2)\n",
        "labelservice = labeling.fit(servicevecs, servicesenttrain)\n",
        "labelservice.transduction_"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:288: ConvergenceWarning: max_iter=2 was reached without convergence.\n",
            "  category=ConvergenceWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
            "  self.label_distributions_ /= normalizer\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQO0h5ONZBGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "servicewordsneg = []\n",
        "servicewordsaff = []\n",
        "for i in range (len(labelservice.transduction_)):\n",
        "  if labelservice.transduction_[i] == 1:\n",
        "    servicewordsaff.append(servicewords[i])\n",
        "  elif labelservice.transduction_[i] == 1:\n",
        "    servicewordsneg.append(servicewords[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egQVHLdHaFhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "foodwordsneg = []\n",
        "foodwordsaff = []\n",
        "for i in range (len(labelfood.transduction_)):\n",
        "  if labelfood.transduction_[i] == 1:\n",
        "    foodwordsaff.append(foodwords[i])\n",
        "  elif labelfood.transduction_[i] == 1:\n",
        "    foodwordsneg.append(foodwords[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpRGjZz-WJqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def razmetkamaker (text, output):\n",
        "  f = open(output, \"a\")\n",
        "  tokreview = sent_tokenize(text)\n",
        "  for sent in tokreview:\n",
        "    toksent = preproc(sent)\n",
        "    sents.append(toksent)\n",
        "  for s in range(len(sents)):\n",
        "    for w in range(len(sents[s])):\n",
        "      if sents[s][w] in servicewordsneg:\n",
        "        string = str(s+1) + '\\\\t' + str(w+1) +'\\\\t' + 'service' + '\\\\t' + '0' + '\\\\n'\n",
        "        f.write(string)\n",
        "      elif sents[s][w] in servicewordsaff:\n",
        "        string = str(s+1) + '\\\\t' + str(w+1) +'\\\\t' + 'service' + '\\\\t' + '1' + '\\\\n'\n",
        "        f.write(string)\n",
        "      elif sents[s][w] in foodwordsneg:\n",
        "        string = str(s+1) + '\\\\t' + str(w+1) +'\\\\t' + 'food' + '\\\\t' + '0' + '\\\\n'\n",
        "        f.write(string)\n",
        "      elif sents[s][w] in foodwordsaff:\n",
        "        string = str(s+1) + '\\\\t' + str(w+1) +'\\\\t' + 'food' + '\\\\t' + '1' + '\\\\n'\n",
        "        f.write(string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jamp2ivcL8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}